import { PlaywrightCrawler } from './src/crawler.js';
import { resolve } from 'path';
import { readFileSync } from 'fs';

/**
 * .env dosyasƒ±ndan config oku ve crawler'ƒ± √ßalƒ±≈ütƒ±r
 */
async function main() {
  // .env dosyasƒ±nƒ± oku
  const envPath = resolve('.env');
  let envContent: string;
  
  try {
    envContent = readFileSync(envPath, 'utf-8');
  } catch (error) {
    console.error('‚ùå .env dosyasƒ± bulunamadƒ±!');
    console.log('üí° √ñnce ≈üunu √ßalƒ±≈ütƒ±r: cp .env.example .env');
    process.exit(1);
  }

  // Env deƒüerlerini parse et
  const config: Record<string, string> = {};
  envContent.split('\n').forEach(line => {
    const trimmed = line.trim();
    if (trimmed && !trimmed.startsWith('#')) {
      const [key, ...valueParts] = trimmed.split('=');
      config[key.trim()] = valueParts.join('=').trim();
    }
  });

  // Validate START_URL
  if (!config.START_URL) {
    console.error('‚ùå .env dosyasƒ±nda START_URL bulunamadƒ±!');
    process.exit(1);
  }

  console.log('\nüìã .env Konfig√ºrasyonu:');
  console.log(`   START_URL: ${config.START_URL}`);
  console.log(`   OUTPUT_DIR: ${config.OUTPUT_DIR || './crawled'}`);
  console.log(`   MAX_DEPTH: ${config.MAX_DEPTH || '3'}`);
  console.log(`   MAX_PAGES: ${config.MAX_PAGES || '100'}`);
  console.log(`   DELAY_MS: ${config.DELAY_MS || '1000'}`);
  console.log(`   SAME_DOMAIN_ONLY: ${config.SAME_DOMAIN_ONLY || 'true'}`);
  console.log(`   OFFLINE_MODE: ${config.OFFLINE_MODE || 'false'}\n`);

  const crawler = new PlaywrightCrawler({
    startUrl: config.START_URL,
    outputDir: resolve(config.OUTPUT_DIR || './crawled'),
    maxDepth: parseInt(config.MAX_DEPTH || '3'),
    maxPages: parseInt(config.MAX_PAGES || '100'),
    sameDomainOnly: config.SAME_DOMAIN_ONLY !== 'false',
    delay: parseInt(config.DELAY_MS || '1000'),
    timeout: parseInt(config.TIMEOUT_MS || '30000'),
    offlineMode: config.OFFLINE_MODE === 'true'
  });

  try {
    console.log('üé≠ Playwright Crawler ba≈ülatƒ±lƒ±yor...\n');
    await crawler.initialize();
    await crawler.start();
    console.log('\n‚ú® Crawling tamamlandƒ±!\n');
  } catch (error) {
    console.error('‚ùå Hata:', error);
    process.exit(1);
  } finally {
    await crawler.close();
  }
}

main();
